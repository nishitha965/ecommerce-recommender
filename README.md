.

ğŸ›’ E-commerce Product Recommender
ğŸ¯ Objective

This project combines a simple product recommendation system with LLM-powered explanations to help users understand why specific items are recommended to them.

It demonstrates how recommendation logic and AI-driven natural language explanations can work together in an e-commerce context.

ğŸš€ Features

ğŸ“¦ Product Catalog: Stores products with names, categories, and prices.

ğŸ‘¤ User Behavior Tracking: Logs user interactions to inform recommendations.

ğŸ¤– LLM-Powered Explanations: Generates personalized explanations for each recommendation.

ğŸ–¥ï¸ Interactive Frontend Dashboard: Built with Streamlit to view recommendations for any user.

âš™ï¸ RESTful Backend API: FastAPI backend serving product and recommendation data.

ğŸ§© Project Structure
ecommerce-recommender/
â”‚
â”œâ”€â”€ app.py                 # Streamlit frontend
â”œâ”€â”€ main.py                # FastAPI backend
â”œâ”€â”€ recommender.py         # Core recommendation logic
â”œâ”€â”€ llm.py                 # LLM-based explanation generation
â”œâ”€â”€ database.py            # SQLite database setup
â”œâ”€â”€ populate_data.py       # Adds sample data to the database
â”œâ”€â”€ requirements.txt       # Project dependencies
â””â”€â”€ README.md              # Project documentation

âš™ï¸ Tech Stack
Component	Technology Used
Frontend UI	Streamlit
Backend API	FastAPI
Database	SQLite
AI Explanation	Mock LLM (replaceable with OpenAI or similar)
Language	Python 3.10+
ğŸ’» Setup Instructions
1ï¸âƒ£ Clone the Repository
git clone https://github.com/<your-username>/ecommerce-recommender.git
cd ecommerce-recommender

2ï¸âƒ£ Create and Activate a Virtual Environment

Windows PowerShell:

python -m venv .venv
.venv\Scripts\Activate.ps1


If script execution is blocked:

Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
.venv\Scripts\Activate.ps1

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Populate Sample Data
python populate_data.py


You should see:

Sample data added.

ğŸ§  Running the Project
ğŸ–¥ï¸ Terminal 1 â€” Start Backend (FastAPI)
uvicorn main:app --reload


Backend will start at:
ğŸ‘‰ http://127.0.0.1:8000

ğŸ’» Terminal 2 â€” Start Frontend (Streamlit)
streamlit run app.py


Frontend will open at:
ğŸ‘‰ http://localhost:8501

ğŸ§  How It Works

The backend (main.py) retrieves user interaction data from the database.

The recommender (recommender.py) finds products based on similar categories or interests.

The LLM (llm.py) generates a human-readable explanation of why each product is recommended.

The frontend (app.py) displays recommendations for a selected user in an interactive UI.

ğŸ“Š Example Output

Input:
User ID = 1

Output:
Recommended Products:

â€œWireless Headphonesâ€ ğŸ§
â†’ Because user 1 interacted with similar products, Wireless Headphones is recommended.

â€œBluetooth Speakerâ€ ğŸ”Š
â†’ Users like you often buy Bluetooth Speaker.

ğŸ”§ Customization

To replace the mock LLM with OpenAI, update llm.py:

import openai
openai.api_key = "your_api_key"


Then use:

response = openai.ChatCompletion.create(...)

ğŸ§¾ Future Improvements

âœ… Integrate real machine learning recommendation models

âœ… Add authentication and user profiles

âœ… Deploy backend and frontend on Render or Vercel

âœ… Store real-time user clickstream data

âœ… Replace mock LLM with OpenAI or Hugging Face model

ğŸ‘¨â€ğŸ’» Author

Nishitha
ğŸ“ Computer Science Engineer
ğŸ’¡ Passionate about AI, Machine Learning, and Smart Applications.